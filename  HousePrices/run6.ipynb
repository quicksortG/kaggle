{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--start--\n",
      "--1--\n",
      "--2--\n",
      "--3--\n",
      "--4--\n",
      "(1434, 61)\n",
      "(1459, 61)\n",
      "-------Linear\n",
      "0.9176407767301069\n",
      "-------Ridge\n",
      "0.9176407767301068\n",
      "-------Lasso\n",
      "-------xgboost\n",
      "-------GradientBoostingRegressor\n",
      "0.9999922420329622\n",
      "(1459, 61)\n",
      "--end-- 11.02367091178894\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "print('--start--')\n",
    "time_start = time.time()\n",
    "\n",
    "df_train = pd.read_csv('gs://sample_machine_learning_input/HousePrices/train.csv')\n",
    "df_test = pd.read_csv('gs://sample_machine_learning_input/HousePrices/test.csv')\n",
    "\n",
    "print('--1--')\n",
    "\n",
    "# データタイプがobjectの列の値をラベル化した数値に変換\n",
    "for i in range(df_train.shape[1]):\n",
    "    if df_train.iloc[:,i].dtypes == object:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df_train.iloc[:,i].values) + list(df_test.iloc[:,i].values))\n",
    "        df_train.iloc[:,i] = lbl.transform(list(df_train.iloc[:,i].values))\n",
    "        df_test.iloc[:,i] = lbl.transform(list(df_test.iloc[:,i].values))\n",
    "\n",
    "\n",
    "print('--2--')\n",
    "#外れデータ除外\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['LotArea']>100000)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['Street']<0.1)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['Utilities']>0.9)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['SalePrice']>700000)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['Electrical']>4.5)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['LowQualFinSF']>560)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4500)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['BsmtFullBath']>2.5)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['BsmtHalfBath']>1.75)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['BedroomAbvGr']>7)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['KitchenAbvGr']>2.75)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['OpenPorchSF']>500)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['EnclosedPorch']>500)].index)\n",
    "df_train = df_train.drop(df_train[(df_train['SaleCondition']>-1) & (df_train['SalePrice']>700000)].index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('--3--')\n",
    "\n",
    "Xmat = pd.concat([df_train, df_test])\n",
    "# 欠損が多いカラムを削除\n",
    "Xmat = Xmat.drop(['LotFrontage','MasVnrArea','GarageYrBlt'], axis=1)\n",
    "Xmat = Xmat.drop(['PoolArea','PoolQC','MoSold','YrSold'], axis=1)\n",
    "Xmat = Xmat.drop(['Fireplaces','FireplaceQu'], axis=1)\n",
    "Xmat = Xmat.drop(['Street','Utilities','Condition2','BsmtHalfBath','3SsnPorch','MiscVal'], axis=1)\n",
    "Xmat = Xmat.drop(['LotShape','LotConfig','BsmtFinSF1','ScreenPorch'], axis=1)\n",
    "Xmat['TotalSF'] = Xmat['TotalBsmtSF'] + Xmat['1stFlrSF'] + Xmat['2ndFlrSF']\n",
    "\n",
    "# 欠損値の少ないカラムのNaNは中央値(median)で埋める\n",
    "Xmat = Xmat.fillna(Xmat.median())\n",
    "\n",
    "X_ch_train = Xmat.iloc[:df_train.shape[0],:]\n",
    "X_ch_test = Xmat.iloc[df_train.shape[0]:,:]\n",
    "\n",
    "\n",
    "\n",
    "print('--4--')\n",
    "#\n",
    "test_id = X_ch_test['Id']\n",
    "df_train_y = X_ch_train['SalePrice']\n",
    "df_test_id = X_ch_test['Id']\n",
    "\n",
    "df_train_x = X_ch_train.drop(['Id','SalePrice'],axis=1)\n",
    "X_ch_test = X_ch_test.drop(['Id','SalePrice'],axis=1)\n",
    "\n",
    "y_train_log = np.log(df_train_y)\n",
    "\n",
    "\n",
    "print(df_train_x.shape)\n",
    "print(X_ch_test.shape)\n",
    "\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_x, df_train_y, random_state=0)\n",
    "\n",
    "for alpha in [0.00001,0.0001,0.001,0.01, 0.1, 1, 3, 7, 10, 100,200, 300, 400 ,500,600, 1000]:\n",
    "    ridge = Ridge(alpha=alpha).fit(X_train, y_train)\n",
    "    #print(\"\\n alpha={}\".format(str(alpha)))\n",
    "    #print(\"Train set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "    #print(\"Test set score: {:.2f}\".format(ridge.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "for alpha in [0.00001,0.0001,0.001,0.01,0.02, 0.5, 1,10,100,200, 300, 400 ,500,600, 1000,5000,10000]:\n",
    "    lasso = Lasso(alpha=alpha).fit(X_train, y_train)\n",
    "    #print(\"\\n alpha={}\".format(str(alpha)))\n",
    "    #print(\"Train set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "    #print(\"Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "    #print(\"Number of features used:{}\".format(np.sum(lasso.coef_ != 0)))\n",
    "    \n",
    "for val_max_depth in [4,5,6]:\n",
    "    for val_n_estimators in [10,100,200,300,500,1000]:\n",
    "        sgr = GradientBoostingRegressor(max_depth=val_max_depth, n_estimators=val_n_estimators)\n",
    "        sgr_data = sgr.fit(df_train_x,df_train_y)    \n",
    "        #print(\"Test set score: {:.2f}\".format(sgr_data.score(X_test, y_test)))\n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "print('-------Linear')\n",
    "lin_model = LinearRegression()\n",
    "lin_model_data = lin_model.fit(df_train_x,y_train_log)\n",
    "print(lin_model.score(df_train_x,y_train_log))\n",
    "\n",
    "print('-------Ridge')\n",
    "ridge_model = Ridge(alpha=0.000001)\n",
    "ridge_model_data = ridge_model.fit(df_train_x,y_train_log)\n",
    "print(ridge_model.score(df_train_x,y_train_log))\n",
    "\n",
    "print('-------Lasso')\n",
    "#clf_model = Lasso(alpha=0.000001) \n",
    "#clf_model_data = clf_model.fit(df_train_x,y_train_log)\n",
    "#print(clf_model.score(df_train_x,y_train_log))\n",
    "clf_model_data = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(df_train_x,y_train_log)\n",
    "\n",
    "\n",
    "print('-------xgboost')\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=1000, max_depth=2, learning_rate=0.1)\n",
    "xgb_model_data=xgb_model.fit(df_train_x,y_train_log)\n",
    "\n",
    "'''\n",
    "#xgb_model = xgb.XGBRegressor()\n",
    "xgboost = xgb.XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006, random_state=42)\n",
    "'''\n",
    "\n",
    "print('-------GradientBoostingRegressor')\n",
    "sgr = GradientBoostingRegressor(max_depth=6, n_estimators=1000)\n",
    "sgr_data = sgr.fit(df_train_x,y_train_log)\n",
    "print(sgr_data.score(df_train_x,y_train_log))\n",
    "'''\n",
    "#score:0.12050\n",
    "blend_models_predict = ((0.4 * lin_model_data.predict(X_ch_test)) \n",
    "                        + (0.1 * ridge_model_data.predict(X_ch_test)) \n",
    "                        + (0.05 * clf_model_data.predict(X_ch_test))\n",
    "                        + (0.4 * xgb_model_data.predict(X_ch_test))\n",
    "                        + (0.05 * sgr_data.predict(X_ch_test)))\n",
    "'''\n",
    "'''\n",
    "#score:0.12039\n",
    "blend_models_predict = ((0.4 * lin_model_data.predict(X_ch_test)) \n",
    "                        + (0.6 * xgb_model_data.predict(X_ch_test)))\n",
    "'''\n",
    "#0.12021\n",
    "blend_models_predict = ((0.3 * lin_model_data.predict(X_ch_test)) \n",
    "                        + (0.05 * ridge_model_data.predict(X_ch_test)) \n",
    "                        + (0.05 * clf_model_data.predict(X_ch_test))\n",
    "                        + (0.5 * xgb_model_data.predict(X_ch_test)))\n",
    "\n",
    "\n",
    "y_test_pred = np.exp(blend_models_predict)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": y_test_pred\n",
    "})\n",
    "submission.to_csv('gs://sample_machine_learning_output/HousePrices/hp_submission10.csv', index=False)\n",
    "########\n",
    "\n",
    "print('--end--',time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
