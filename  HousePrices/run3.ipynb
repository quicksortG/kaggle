{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Start--\n",
      "count      1460.000000\n",
      "mean     180921.195890\n",
      "std       79442.502883\n",
      "min       34900.000000\n",
      "25%      129975.000000\n",
      "50%      163000.000000\n",
      "75%      214000.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n",
      "(1460, 81)\n",
      "(1459, 80)\n",
      "経過時間:1.549705982208252[sec]\n",
      "--End--\n"
     ]
    }
   ],
   "source": [
    "#invite people for the Kaggle party\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"--Start--\")\n",
    "start = time.time()\n",
    "\n",
    "# データの読み込み\n",
    "test = pd.read_csv('gs://sample_machine_learning_input/HousePrices/test.csv')\n",
    "df_train = pd.read_csv('gs://sample_machine_learning_input/HousePrices/train.csv')\n",
    "\n",
    "train_id = df_train['Id']\n",
    "test_id = test['Id']\n",
    "\n",
    "#SalePriceカラム要約\n",
    "print(df_train['SalePrice'].describe())\n",
    "print(df_train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "\n",
    "df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
    "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
    "df_train.isnull().sum().max()\n",
    "\n",
    "test = test.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
    "test = test.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
    "test.isnull().sum().max()\n",
    "\n",
    "\n",
    "saleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\n",
    "low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\n",
    "high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\n",
    "\n",
    "df_train.sort_values(by = 'GrLivArea', ascending = False)[:2]\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 524].index)\n",
    "df_train['SalePrice'] = np.log(df_train['SalePrice'])\n",
    "df_train['GrLivArea'] = np.log(df_train['GrLivArea'])\n",
    "test['GrLivArea'] = np.log(test['GrLivArea'])\n",
    "df_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\n",
    "df_train['HasBsmt'] = 0 \n",
    "df_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1\n",
    "\n",
    "test['HasBsmt'] = pd.Series(len(test['TotalBsmtSF']), index=test.index)\n",
    "test['HasBsmt'] = 0 \n",
    "test.loc[test['TotalBsmtSF']>0,'HasBsmt'] = 1\n",
    "\n",
    "df_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])\n",
    "test.loc[test['HasBsmt']==1,'TotalBsmtSF'] = np.log(test['TotalBsmtSF'])\n",
    "#df_train = pd.get_dummies(df_train)\n",
    "#test = pd.get_dummies(test)\n",
    "\n",
    "# データタイプがobjectの列の値をラベル化した数値に変換\n",
    "for i in range(df_train.shape[1]):\n",
    "    if df_train.iloc[:,i].dtypes == object:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df_train.iloc[:,i].values) + list(test.iloc[:,i].values))\n",
    "        df_train.iloc[:,i] = lbl.transform(list(df_train.iloc[:,i].values))\n",
    "        test.iloc[:,i] = lbl.transform(list(test.iloc[:,i].values))\n",
    "        \n",
    "\n",
    "Xmat = pd.concat([df_train, test])  \n",
    "#欠損値の少ないカラムのNaNは中央値(median)で埋める\n",
    "Xmat = Xmat.fillna(Xmat.median())\n",
    "#trainデータとtestデータを含んでいるXmatを、再度trainデータとtestデータに分割\n",
    "df_train = Xmat.iloc[:df_train.shape[0],:]\n",
    "test = Xmat.iloc[df_train.shape[0]:,:]\n",
    "\n",
    "y = df_train['SalePrice']\n",
    "df_train = df_train.drop(['Id','SalePrice'],axis=1)\n",
    "test = test.drop(['Id','SalePrice'],axis=1)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model_data=xgb_model.fit(df_train, y)\n",
    "\n",
    "\n",
    "result = xgb_model.predict(test)\n",
    "result = np.exp(result)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": result\n",
    "})\n",
    "submission.to_csv('gs://sample_machine_learning_output/HousePrices/hp_submission8.csv', index=False)\n",
    "########\n",
    "elapsed_time = time.time() - start\n",
    "print (\"経過時間:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "print(\"--End--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
